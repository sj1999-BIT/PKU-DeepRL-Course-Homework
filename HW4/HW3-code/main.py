"""
Idea: use MPC + CEM for planning
1. successful initial training multiple DNN with random transitions

"""
import os.path
import re
import torch

from data import append_values_to_file
from dataProcessor import DataProcessor
from neural_network import DynamicsNetwork, PolicyNetwork, ValueNetwork
from tqdm import tqdm


import gymnasium as gym


def initialise_DNN_arr_and_val(env: gym.Env, transitionProcessor: DataProcessor, ensemble_size=10,
                       epoch_num=100, batch_size=64):
    """
    Initializes and pre-trains an ensemble of Dynamic Neural Networks for model-based reinforcement learning.
    Each trajectory should be generated by the policynetwork. In this way we can have the log_probability for the
    old policyNetwork for training.

    :param ensemble_size: for boostrap ensembles, we initiate multiple dynamic nn and train them simultaneously
    :param batch_size: we generate batch of 64 for training
    :param epoch_num: total number of epoch for training
    :param env: The OpenAI Gym environment
    :param transitionProcessor: Object that handles transition data processing
    :return: Array of trained Dynamic Neural Network models
    """
    # get the state dimension and action dimension of the target environment
    # we create 10 independent DNN for bootstrap ensembles
    state_dim = env.observation_space.shape[0]
    action_dim = env.action_space.shape[0]

    # for boostrap ensembles, we initiate multiple dynamic nn and train them simultaneously
    DNN_arr = [DynamicsNetwork(env, model_name=model_index) for model_index in
               range(ensemble_size)]

    vNet = ValueNetwork(env)

    path ="."

    # iteration = 0
    # path = f"./data_{iteration}"
    # while os.path.exists(path):
    #     iteration +=1
    #     path = f"./data_{iteration}"
    #
    # os.makedirs(path)

    for step in tqdm(range(epoch_num), desc=f"training {ensemble_size} dynamic NN for ensemble bootstrap"):

        # train Dynamic NN
        for model_index in range(ensemble_size):
            # training current model
            cur_model = DNN_arr[model_index]
            # generate batch data for training
            sample = transitionProcessor.random_sample(batch_size=batch_size)

            # generate MSE loss based on the predicted next state and actual next state
            loss = cur_model.get_loss(sample)

            # backpropagation
            cur_model.optimizer.zero_grad()
            loss.backward()
            cur_model.optimizer.step()

            append_values_to_file(loss.detach().item(), f"{path}/model_{model_index}_loss.txt")


        # train value Network
        sample = transitionProcessor.random_sample(batch_size=batch_size)

        # generate MSE loss based on the predicted next state and actual next state
        loss = vNet.get_loss(sample)

        # backpropagation
        vNet.optimizer.zero_grad()
        loss.backward()
        vNet.optimizer.step()

        append_values_to_file(loss.detach().item(), f"{path}/value_loss.txt")
    # save model weights
    for model_index in range(ensemble_size):
        # training current model
        cur_model = DNN_arr[model_index]
        cur_model.save_weights()

    vNet.save_weights()

    return DNN_arr, vNet


def initialise_NN(env: gym.Env, path="./", epoch_num=100, batch_size=64, ensemble_size=10):
    """
    :return: create pNet, vNet, dNet_arr for training. Load them if they already exist
    """
    pNet = PolicyNetwork(env)

    # get the state dimension and action dimension of the target environment
    # we create 10 independent DNN for bootstrap ensembles
    state_dim = env.observation_space.shape[0]
    action_dim = env.action_space.shape[0]

    # for boostrap ensembles, we initiate multiple dynamic nn and train them simultaneously
    DNN_arr = [DynamicsNetwork(env, model_name=model_index) for model_index in
               range(ensemble_size)]


    # if policyNetwork exist, load
    target_path = os.path.join(path, "Policy_nn_weight.pth")
    if os.path.exists(target_path):
        pNet.load_weights(target_path)

def load_NN(env: gym.Env, model_path="./"):
    if not os.path.exists(model_path):
        raise Exception(f"{model_path} path not exist, cannot load model")

    # load model

    valueNet = ValueNetwork(env)
    policyNet = PolicyNetwork(env)

    is_vNet_loaded = False
    is_pNet_loaded = False

    dynamicArr = []

    for model_weight_filename in os.listdir(model_path):
        if model_weight_filename == "Value_nn_weight.pth":
            valueNet.load_weights(filepath=os.path.join(model_path, model_weight_filename))
            is_vNet_loaded = True

        if model_weight_filename == "Policy_nn_weight.pth":
            policyNet.load_weights(filepath=os.path.join(model_path, model_weight_filename))
            is_pNet_loaded = True

        if re.match(r'^dynamics_nn_weight_(\d+)\.pth$', model_weight_filename) is not None:
            dNN = DynamicsNetwork(env)
            dNN.load_weights(filepath=os.path.join(model_path, model_weight_filename))
            dynamicArr.append(dNN)

    return policyNet, valueNet, dynamicArr, is_vNet_loaded and is_pNet_loaded





if __name__=="__main__":
    test_env = gym.make("Hopper-v5", render_mode=None)

    load_NN(test_env, "data/official_start_models")





